# MCP Agent Development Guide

## Project Overview

This project implements an AI agent with a modern web UI (React, Tailwind CSS) that utilizes [Model Context Protocol (MCP)](https://github.com/modelcontextprotocol/spec) servers to extend its capabilities. The AI agent is designed to be:

1. **Web-based**: Runs in a web container (Docker), serving a React frontend.
2. **Modern UI/UX**: Features a responsive design similar to ChatGPT/Ollama, including dark mode, message streaming, and real-time "thinking" display.
3. **LLM Backend**: Uses `llama-cpp-python` to run quantized models (e.g., GGUF format).
4. **Extensible**: Can leverage any MCP server defined in `mcp.json` for tool use.

## Core Components

- **Backend (FastAPI - `app/`)**:
  - `main.py`: FastAPI app setup, lifespan management, static file serving, API routing.
  - `api/api.py`: Defines API endpoints (`/api/v1/chat`, `/api/v1/stream`).
  - `services/`: Contains core logic for inference, model loading, and MCP interaction.
    - `ModelService`: Handles LLM loading and generation (`llama-cpp-python`).
    - `MCPService`: Manages MCP server connections and tool execution.
    - `InferenceService`: Implements the ReAct pattern, orchestrating model and tools.
  - `core/config.py`: Centralized configuration using Pydantic `BaseSettings`.
  - `static/`: Directory served by FastAPI containing the **built** frontend files (generated by `npm run build`).
- **Frontend (React - `frontend/`)**:
  - `src/App.tsx`: Main application component, state management, API interaction (EventSource for streaming).
  - `src/components/`: Reusable UI components (`Message`, `ThinkingIndicator`, `EmptyState`, etc.).
  - `src/index.css`: Global styles and Tailwind CSS configuration.
  - `tailwind.config.js`: Tailwind CSS theme and plugin customization.
  - `vite.config.ts`: Vite build tool configuration.
- **Configuration (`.`, `app/`)**:
  - `.env`: Environment variables for configuration (loaded by `config.py`).
  - `mcp.json`: Defines available MCP servers.
  - `react_output.gbnf`: GBNF grammar file for structured LLM output.
  - `QwQ.md`: (If applicable) Documentation specific to the QwQ model variant.
- **Execution & Deployment**:
  - `run.sh`: Script to run backend and frontend **development** servers concurrently.
  - `Dockerfile`: Multi-stage Dockerfile to build the frontend and package the backend with static files for production deployment.

## Key Features

### Modern UI/UX

- **Responsive Design**: Adapts layout for desktop (sidebar + main chat) and mobile (overlay sidebar).
- **Ollama/ChatGPT Style**: Clean interface, distinct user/AI messages with icons.
- **Dark Mode**: Class-based dark mode support toggled by OS preference (can be extended with a manual toggle).
- **Real-time Thinking**: Displays the AI's thought process (`thinking`) streamed from the backend via Server-Sent Events (SSE) while generating a response.
- **Streaming Responses**: Final AI responses are streamed token-by-token (or chunk-by-chunk) using SSE.
- **Loading Indicators**: Input field disabled and send button shows a spinner during AI processing.
- **Interactive Empty State**: Provides example prompts that users can click to start a conversation.

### MCP Server Integration

- The AI agent uses the MCP protocol to interact with external tools
- MCP servers are defined in `mcp.json` and loaded dynamically
- No hardcoded MCP servers - all tools must be discovered at runtime
- Tool schemas are cached to improve performance and reduce latency

### ReAct Pattern Implementation

The AI agent uses the ReAct (Reasoning + Acting) pattern:

1. **Thought**: The AI analyzes the query, available tools, and previous observations
2. **Action**: The AI either calls a tool or provides a final answer
3. **Observation**: Results from tool execution are provided back to the AI
4. **Repeat**: The process continues until a final answer is reached

### Logging System

- All interactions are logged to a centralized `meta.json` file per session
- Logs include user queries, AI responses, tool calls, and observations
- Logs are stored in `logs/api_logs/{session_id}/meta.json`

## Configuration Management (`app/core/config.py`)

All major configuration parameters are centralized in `app/core/config.py` using Pydantic's `BaseSettings`. This allows configuration via environment variables or a `.env` file.

**Key Configuration Variables:**

*   **Model Settings:**
    *   `MODEL_FILENAME`: Name of the model file (e.g., `QwQ-LCoT-7B-Instruct-IQ4_NL.gguf`).
    *   `MODEL_PATH`: Full path to the model file. If not set, calculated from `MODEL_DIR` and `MODEL_FILENAME`.
    *   `MODEL_DIR`: Directory where models are stored (defaults to `./models` or `/app/models` in Docker).
    *   `N_CTX`: Model context window size (default: 32768).
    *   `GPU_LAYERS`: Number of layers to offload to GPU (default: -1 for all possible).
    *   `GRAMMAR_PATH`: Path to the GBNF grammar file (default: `react_output.gbnf`).
*   **LLM Generation Parameters:**
    *   `MODEL_MAX_TOKENS`: Max tokens to generate (default: 1024).
    *   `MODEL_TEMPERATURE`: Sampling temperature (default: 0.7).
    *   `MODEL_TOP_P`: Top-P sampling nucleus (default: 0.9).
    *   `MODEL_TOP_K`: Top-K sampling limit (default: 40).
    *   `MODEL_MIN_P`: Min-P sampling (default: 0.05, model must support).
*   **ReAct Loop:**
    *   `REACT_MAX_ITERATIONS`: Maximum number of thought/action cycles (default: 10).
*   **MCP:**
    *   `MCP_CONFIG_FILENAME`: Name of the MCP configuration file (default: `mcp.json`).
    *   `MCP_CONFIG_PATH`: Full path to the MCP config file (calculated).
*   **Logging:**
    *   `LOG_LEVEL`: Logging level (e.g., INFO, DEBUG) (default: INFO).
    *   `LOG_DIR`: Directory for log files (default: `logs`).
*   **API:**
    *   `API_V1_PREFIX`: Prefix for all API routes (default: `/api/v1`).

**Usage in Code:**

Import the settings object and access attributes directly:

```python
from app.core.config import settings

# Example usage
max_iterations = settings.react_max_iterations
model_path = settings.model_path
```

## Development Environment Setup

1. **Prerequisites**: Python 3.9+, Node.js 18+, npm.
2. **Backend Setup**:
   * Create a Python virtual environment: `python -m venv venv`
   * Activate the environment: `source venv/bin/activate` (Linux/macOS) or `venv\Scripts\activate` (Windows)
   * Install Python dependencies: `pip install -r requirements.txt`
3. **Frontend Setup**:
   * Navigate to the frontend directory: `cd frontend`
   * Install Node.js dependencies: `npm install`
   * Return to the root directory: `cd ..`
4. **Model Setup**: Download the required GGUF model file (e.g., `QwQ-LCoT-7B-Instruct-IQ4_NL.gguf`) and place it in the directory specified by `MODEL_DIR` (default: `./models`).
5. **Configuration**: Create a `.env` file in the root directory or set environment variables according to `app/core/config.py`.
6. **(Optional) MCP Servers**: Ensure any required MCP servers are running and configured in `mcp.json`.

## Running the Application

### Development Mode (with Hot Reloading)

Use the provided script to run both backend and frontend development servers:

```bash
chmod +x run.sh
./run.sh
```

*   Access the frontend UI at: `http://localhost:5173` (or the next available port shown in the console).
*   Access the backend API (e.g., for testing) at: `http://localhost:8000/api/v1/...`
*   API Docs: `http://localhost:8000/api/v1/docs`

Changes to frontend code (`frontend/src/`) will trigger hot reloading in the browser.
Changes to backend code (`app/`) might require restarting `run.sh` unless Uvicorn's reload flag is enabled (currently `False` in `app/main.py` for stability).

### Production Mode (Docker)

The `Dockerfile` uses a multi-stage build:

1. **Builds** the frontend React application into static files.
2. **Packages** the Python backend application.
3. **Copies** the built frontend static files into the final Python image.
4. **Configures** FastAPI to serve the static frontend files and the API.

**Build the Docker image:**

```bash
docker build -t mcp-agent:latest .
```

**Run the Docker container:**

```bash
docker run -p 8000:8000 \
       -v $(pwd)/models:/app/models \
       -v $(pwd)/logs:/app/logs \
       -v $(pwd)/mcp.json:/app/mcp.json \
       -e "LOG_LEVEL=INFO" \
       --name mcp-agent-container \
       mcp-agent:latest
```

*   `-p 8000:8000`: Maps the host port 8000 to the container port 8000.
*   `-v $(pwd)/models:/app/models`: Mounts the local `models` directory into the container (adjust path if needed). **Important:** Ensure the model file exists locally.
*   `-v $(pwd)/logs:/app/logs`: Mounts the local `logs` directory for persistent logging.
*   `-v $(pwd)/mcp.json:/app/mcp.json`: Mounts the MCP configuration file.
*   `-e "LOG_LEVEL=INFO"`: Sets the logging level via environment variable.
*   `--name mcp-agent-container`: Assigns a name to the container.

Access the application in your browser at `http://localhost:8000`.

## Development Rules

1. **No Hardcoding of MCP Servers**:
   - The system must detect and use MCP servers defined in `mcp.json`
   - The user can add or remove MCP servers at any time

3. **Simplified Tool Descriptions**:
   - Initially provide only a list of available tools with brief descriptions
   - Provide detailed tool information only when a specific tool is selected

4. **Centralized Logging**:
   - All logs for a session must be stored in a single `meta.json` file
   - No file fragmentation or redundant logs

5. **Proper Error Handling**:
   - All errors must be properly captured and formatted for the user
   - Failed tool executions should not crash the system

6. **No Test Mocking**:
   - Tests must run against the actual system, not mocked components
   - Tests must not be skipped and should reflect real production scenarios

8. **Variable Naming Consistency**:
   - Always ensure that variable names are consistent throughout the codebase
   - When a function returns a variable, make sure to use the same name when referring to it in the calling code
   - Pay special attention to function return values to avoid `NameError` exceptions

9. **Avoid Duplicate Definitions**:
   - Do not redefine functions or methods within other functions
   - Import utilities from the appropriate modules instead of redefining them
   - When modifying methods, scan the entire function for duplicate helper functions

10. **Regular Code Cleanup**:
   - Regularly scan the codebase for unused imports, variables, and functions
   - Remove or comment out unused code to improve readability and performance
   - Use linters and type checkers to identify potential issues before they cause runtime errors

11. **Proper Dependency Injection**:
   - Never use FastAPI's `Depends` in service class constructors directly
   - Service classes should import settings directly from `app.core.config`
   - The application uses singleton patterns for services, with instances created in `lifespan`
   - Use dependency injection only in API route functions or middleware

12. **Robust Logging Implementation**:
   - Always use defensive programming techniques when handling data of uncertain structure
   - Use duck typing and attribute/key access within try-except blocks instead of explicit type checking
   - Design functions to accept broader types using protocol/interface patterns
   - Implement graceful fallback strategies for unexpected data structures
   - When dealing with serialization, ensure proper error handling for non-serializable types

13. **Service Interface Contracts**:
   - When creating methods that other services depend on, document the method's contract clearly
   - Maintain backward compatibility when modifying existing service methods
   - Always implement all expected methods in services that other components depend on
   - Use descriptive error messages when a required method is missing
   - Check service interfaces during system startup rather than runtime where possible

## Model Requirements

- The project uses a quantized ONNX model: `gemma-3-1b-it-ONNX/model_q4f16.onnx`
- The model is ~1GB in size and should be downloaded at runtime, not hosted on GitHub
- The model should be loaded into memory only when needed

## Code Structure and Standards

- Code should be well-structured and maintainable
- Follow proper error handling and logging practices
- Avoid duplicate code and ensure good separation of concerns
- All user-facing messages should adapt to the user's language
- Internal system messages should be in English

## Important Notes

- The agent must be able to run in a web container
- The agent must be OS-agnostic
- The agent must dynamically adapt to available MCP servers
- Always follow the ReAct pattern for reasoning and tool use 